{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import initial dependencies\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from pprint import pprint\n",
    "from api_key import omdb_key\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a path to academy awards csv and read it into a pandas dataframe\n",
    "awards_csv = \"academy_awards_data_2.csv\"\n",
    "awards_df = pd.read_csv(awards_csv, usecols = ['Nominee', 'Year', 'Category', 'Won?'], encoding = 'latin-1')\n",
    "\n",
    "# create another dataframe that only includes nominees in the Best Picture category\n",
    "award_data = awards_df.loc[awards_df[\"Category\"] == \"Best Picture\", :]\n",
    "\n",
    "# create list of best picture nominees\n",
    "best_picture_noms = award_data[\"Nominee\"]\n",
    "\n",
    "# print(best_picture_noms)\n",
    "# print(best_picture_noms[77])\n",
    "# award_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO NEED TO RUN THIS CELL AGAIN BECAUSE DATA IS ALREADY READ INTO CSV BELOW, \n",
    "# BUT TOTALLY FEEL FREE TO TEST IF YOU'VE INCLUDED ADDITIONAL/DIFFERENT AWARD CATEGORIES\n",
    "\n",
    "# print the corresponding number for each movie  \n",
    "movie_number = 1\n",
    "\n",
    "# empty lists for holding movie data\n",
    "box_office = []\n",
    "genre = []\n",
    "meta_score = []\n",
    "imdb_rating = []\n",
    "title = []\n",
    "poster_url = []\n",
    "rated = []\n",
    "release_date = []\n",
    "studio = []\n",
    "\n",
    "best_picture_noms = award_data[\"Nominee\"]\n",
    "base_url = \"http://www.omdbapi.com/?\"\n",
    "\n",
    "    \n",
    "# print statement as each movie is processed\n",
    "print(f\"Beginning Data Retrieval\")\n",
    "print(f\"==============================\")\n",
    "\n",
    "# loop through the movies in the best picture noms dataframe \n",
    "for movie in best_picture_noms:\n",
    "    \n",
    "    params = {\n",
    "    \"apikey\" : omdb_key,\n",
    "    \"t\" : movie\n",
    "    } \n",
    "    \n",
    "    # try statement for each potential movie\n",
    "    try: \n",
    "        omdb_data_raw = requests.get(base_url, params=params)\n",
    "        omdb_data = omdb_data_raw.json()\n",
    "        box_office.append(omdb_data[\"BoxOffice\"])\n",
    "        genre.append(omdb_data[\"Genre\"])\n",
    "        meta_score.append(omdb_data[\"Metascore\"])\n",
    "        imdb_rating.append(omdb_data[\"imdbRating\"])\n",
    "        title.append(omdb_data[\"Title\"])\n",
    "        poster_url.append(omdb_data[\"Poster\"])\n",
    "        rated.append(omdb_data[\"Rated\"]) \n",
    "        release_date.append(omdb_data[\"Released\"]) \n",
    "        studio.append(omdb_data[\"Production\"])\n",
    "        print_title = omdb_data[\"Title\"]\n",
    "        \n",
    "        print(f\"Processing Record {movie_number} | {print_title}\")\n",
    "        print(omdb_data_raw.url) \n",
    "        \n",
    "        # increase movie number by one each loop\n",
    "        movie_number = movie_number + 1\n",
    "        \n",
    "#         to avoid 60 rpm api limit i'm waiting just over 1 second per loop\n",
    "#         https://www.pythoncentral.io/pythons-time-sleep-pause-wait-sleep-stop-your-code/)\n",
    "        time.sleep(1.01)\n",
    "        \n",
    "    # skip if no movie is found or if data is missing\n",
    "    except:\n",
    "        print(\"Data missing or movie not found. Skipping...\")\n",
    "    continue\n",
    "    \n",
    "print(f\"==============================\")\n",
    "print(f\"Data Retrieval Complete\")\n",
    "print(f\"==============================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# NO NEED TO RUN THIS CELL AGAIN BECAUSE DATA IS ALREADY READ INTO CSV BELOW, \n",
    "# BUT TOTALLY FEEL FREE TO TEST IF YOU'VE INCLUDED ADDITIONAL/DIFFERENT AWARD CATEGORIES\n",
    "\n",
    "# converting filtered api data into dataframe\n",
    "filtered_omdb_data_df= pd.DataFrame ({\n",
    "    \"Title\": title,\n",
    "    \"Genre\": genre,\n",
    "    \"Meta_Score\": meta_score,\n",
    "    \"imdb_Rating\": imdb_rating,\n",
    "    \"Box_Office\" : box_office,\n",
    "    \"Rated\" : rated,\n",
    "    \"Studio\" : studio,\n",
    "    \"Release_Date\" : release_date,\n",
    "    \"Poster_URL\" : poster_url\n",
    "})\n",
    "\n",
    "# coverting dataframe into csv-- this step isn't necessary, but did it so i'm not constantly dealing with the api directly\n",
    "filtered_omdb_data_df.to_csv('filtered_omdb_data.csv', index=False)\n",
    "# filtered_omdb_data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# created a path to the filteredd api csv and read it into a pandas dataframe\n",
    "filtered_omdb_csv = \"filtered_omdb_data.csv\"\n",
    "filtered_omdb_csv_df = pd.read_csv(filtered_omdb_csv)\n",
    "# filtered_omdb_csv_df.count()\n",
    "# award_data.count()\n",
    "\n",
    "# merged the filtered api data csv and awards data csv into a single dataset\n",
    "merged_movie_data_df = pd.merge(filtered_omdb_csv_df, award_data, left_on=\"Title\", right_on=\"Nominee\")\n",
    "# merged_movie_data_df.to_csv('merged_movie_data.csv', index=False)\n",
    "# merged_movie_data_df.head()\n",
    "\n",
    "# import Eric's csv that adds a seasons column to \"merged_movie_data_df\"\n",
    "seasons_omdb_csv = \"Seasons_Movie_Data_2.csv\"\n",
    "seasons_omdb_csv_df = pd.read_csv(seasons_omdb_csv)\n",
    "# seasons_omdb_csv_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up Rated category.\n",
    "seasons_omdb_csv_df['Rated'] = seasons_omdb_csv_df['Rated'].replace(\n",
    "    {'NOT RATED': 'Not Rated', 'PASSED': 'Passed', 'UNRATED': 'Not Rated', 'Unrated': 'Not Rated', 'APPROVED': 'Approved'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe for winning and losing nominees\n",
    "winning_noms = seasons_omdb_csv_df[seasons_omdb_csv_df[\"Won?\"] == \"YES\"]\n",
    "# winning_noms\n",
    "\n",
    "losing_noms = seasons_omdb_csv_df[seasons_omdb_csv_df[\"Won?\"] == \"NO\"]\n",
    "# losing_noms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=3.5733867271080175, pvalue=0.0005327364755244779)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winning_noms_imdb = winning_noms['imdb_Rating']\n",
    "losing_noms_imdb = losing_noms['imdb_Rating']\n",
    "\n",
    "stats.ttest_ind(winning_noms_imdb, losing_noms_imdb, equal_var=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count of rated (R, PG, G, etc.) comparison nominees Won vs. Lost \n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    " \n",
    "# set height of bar\n",
    "height_winning_rated = [22, 19, 12, 9, 7, 2, 6]\n",
    "height_losing_rated = [89, 86, 67, 38, 39, 42, 20]\n",
    "\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(height_winning_rated))\n",
    "r2 = [x + barWidth for x in r1]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, height_winning_rated, color='navy', width=barWidth, edgecolor='white', label='Winning Noms')\n",
    "plt.bar(r2, height_losing_rated, color='orange', width=barWidth, edgecolor='white', label='Losing Noms')\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.title(\"'Best Picture' Nominee Movie Rating (1927-2010)\", fontweight='bold')\n",
    "plt.xlabel('Movie Rating', fontweight='bold')\n",
    "plt.ylabel(\"Count of Movie Rating\", fontweight='bold')\n",
    "\n",
    "plt.xticks([r + barWidth for r in range(len(height_winning_rated))], ['R', 'Not Rated', 'PG', 'PG-13', 'Passed', 'Approved', 'G'])\n",
    "\n",
    "#create legend, show graphic, and push to .png\n",
    "plt.legend()\n",
    "plt.savefig(\"count_of_rated_grouped.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "winter_noms = seasons_omdb_csv_df[seasons_omdb_csv_df[\"Seasons\"] == \"Winter\"]\n",
    "spring_noms = seasons_omdb_csv_df[seasons_omdb_csv_df[\"Seasons\"] == \"Spring\"]\n",
    "summer_noms = seasons_omdb_csv_df[seasons_omdb_csv_df[\"Seasons\"] == \"Summer\"]\n",
    "fall_noms = seasons_omdb_csv_df[seasons_omdb_csv_df[\"Seasons\"] == \"Fall\"]\n",
    "\n",
    "winter_rated = winter_noms['Rated'].value_counts()\n",
    "# print(winter_rated)\n",
    "\n",
    "spring_rated = spring_noms['Rated'].value_counts()\n",
    "# print(spring_rated)\n",
    "\n",
    "summer_rated = summer_noms['Rated'].value_counts()\n",
    "# print(summer_rated)\n",
    "\n",
    "fall_rated = fall_noms['Rated'].value_counts()\n",
    "# print(fall_rated)\n",
    "\n",
    "# rated_as_index_ = merged_movie_data_df.set_index('Rated').groupby(['Rated'])\n",
    "# rated_as_index.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count of rated (R, PG, G, etc.) by season\n",
    "\n",
    "# set width of bar\n",
    "barWidth = 0.25\n",
    "\n",
    "# set height of bar\n",
    "height_winter_rated = [60, 36, 30, 25, 11, 7, 4]\n",
    "height_spring_rated = [12, 12, 22, 5, 10, 13, 5]\n",
    "height_summer_rated = [14, 16, 19, 7, 13, 10, 10]\n",
    "height_fall_rated = [25, 15, 30, 10, 10, 16, 7]\n",
    "\n",
    " \n",
    "# Set position of bar on X axis\n",
    "r1 = np.arange(len(height_winter_rated))\n",
    "r2 = [x + barWidth for x in r1]\n",
    "r3 = [x + barWidth for x in r2]\n",
    "r4 = [x + barWidth for x in r3]\n",
    " \n",
    "# Make the plot\n",
    "plt.bar(r1, height_winter_rated, color='navy', width=barWidth, edgecolor='white', label='Winter')\n",
    "plt.bar(r2, height_spring_rated, color='orange', width=barWidth, edgecolor='white', label='Spring')\n",
    "plt.bar(r3, height_summer_rated, color='red', width=barWidth, edgecolor='white', label='Summer')\n",
    "plt.bar(r4, height_fall_rated, color='black', width=barWidth, edgecolor='white', label='Fall')\n",
    "\n",
    " \n",
    "# Add xticks on the middle of the group bars\n",
    "plt.title(\"'Best Picture' Nominee Movie Rating by Season (1927-2010)\", fontweight='bold')\n",
    "plt.xlabel('Movie Rating', fontweight='bold')\n",
    "plt.ylabel(\"Count of Movie Rating\", fontweight='bold')\n",
    "\n",
    "plt.xticks([r + barWidth for r in range(len(height_winter_rated))], ['R', 'PG', 'Not Rated', 'PG-13', 'Approved', 'Passed', 'G'])\n",
    "\n",
    "#create legend, show graphic, and push to .png\n",
    "plt.legend()\n",
    "plt.savefig(\"count_of_rated_by_season.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
